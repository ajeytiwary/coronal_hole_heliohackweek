{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import sunpy.map\n",
    "import sunpy.sun\n",
    "from sunpy.map.maputils import all_coordinates_from_map\n",
    "from sunpy.coordinates import get_horizons_coord\n",
    "import glob\n",
    "import hamada_hist_matching\n",
    "from reproject import reproject_interp\n",
    "from reproject.mosaicking import reproject_and_coadd\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.wcs import WCS\n",
    "import boto3\n",
    "from boto3 import session\n",
    "session = boto3.session.Session(region_name='us-east-1')\n",
    "s3client = session.client('s3')\n",
    "\n",
    "class hamada():\n",
    "    \n",
    "    def __init__(self, filename='cumulative_hist.npz'):\n",
    "        # Read\n",
    "        npzfile = np.load(filename)\n",
    "        self.cdf_eit = npzfile['cdf_eit']\n",
    "        self.bin_eit = npzfile['bins_eit']\n",
    "        self.cdf_euvil = npzfile['cdf_euvil']\n",
    "        self.bin_euvil = npzfile['bins_euvil']\n",
    "        self.nb_channels, self.nb_bins = self.bin_eit.shape\n",
    "        \n",
    "    # Histogram matching (Hamada et al., 2019)\n",
    "    def hist_matching(self, data_eit, channel_nb):\n",
    "        \n",
    "        # Standardize\n",
    "        log_eit = np.log10(data_eit)\n",
    "        mean_log_eit = np.nanmean(log_eit)\n",
    "        std_log_eit = np.nanstd(log_eit)\n",
    "        norm_log_eit = (log_eit - mean_log_eit) / std_log_eit\n",
    "        \n",
    "        # Extract finite values\n",
    "        where_mask = np.isfinite(norm_log_eit)\n",
    "        mask_log_eit = norm_log_eit[where_mask]\n",
    "\n",
    "        # Bins\n",
    "        bin_eit = (self.bin_eit[channel_nb, :-1] + self.bin_eit[channel_nb, 1:]) / 2\n",
    "        bin_euvil = (self.bin_euvil[channel_nb, :-1] + self.bin_euvil[channel_nb, 1:]) / 2\n",
    "        \n",
    "        # Histogram matching\n",
    "        cdf_tmp = np.interp(mask_log_eit.flatten(), bin_eit.flatten(),\n",
    "                            self.cdf_eit[channel_nb, :].flatten())\n",
    "        norm_log_adjusted = np.interp(cdf_tmp, self.cdf_euvil[channel_nb, :].flatten(),\n",
    "                                      bin_euvil.flatten())\n",
    "        \n",
    "        # Adjust data\n",
    "        norm_log_eit[where_mask] = norm_log_adjusted\n",
    "        data_eit_adjusted = 10.**(norm_log_eit*std_log_eit + mean_log_eit)\n",
    "        \n",
    "        return data_eit_adjusted\n",
    "    \n",
    "def wavelet_enhancement(img):\n",
    "    \n",
    "    # incomplete\n",
    "    img_enhanced = img\n",
    "    \n",
    "    return img_enhanced\n",
    "\n",
    "# Masking function\n",
    "def mask_outside_disk(inst_map):\n",
    "    # Find coordinates and radius\n",
    "    hpc_coords = all_coordinates_from_map(inst_map)\n",
    "    r = np.sqrt(hpc_coords.Tx ** 2 + hpc_coords.Ty ** 2) / inst_map.rsun_obs\n",
    "    \n",
    "    # Mask everything outside of the solar disk\n",
    "    mask = ma.masked_greater_equal(r, 1)\n",
    "    ma.set_fill_value(mask, np.nan)\n",
    "    where_disk = np.where(mask.mask == 1)\n",
    "    \n",
    "    return where_disk\n",
    "\n",
    "\n",
    "def make_hist(norm_log_inst, bins_inst):\n",
    "    \n",
    "    where_mask = np.isfinite(norm_log_inst)\n",
    "    arr = norm_log_inst[where_mask]\n",
    "    hist, bins = np.histogram(arr, bins=bins_inst, density=True)\n",
    "    width = bins[1] - bins[0]\n",
    "    \n",
    "    return hist*width\n",
    "\n",
    "\n",
    "# Nb. of channels\n",
    "nb_channels = 3\n",
    "\n",
    "# Find sample data\n",
    "path_to_files = '/home/btremblay/Documents/dir.HelioHackWeek/sampledata/'\n",
    "filenames_eit_0 = sorted(glob.glob(path_to_files+'eit_l1*'))\n",
    "filenames_euvil_0 = sorted(glob.glob(path_to_files+'*eu_L.fts'))\n",
    "filenames_euvir_0 = sorted(glob.glob(path_to_files+'*eu_R.fts'))\n",
    "# Benoit: Needs fixing\n",
    "filenames_eit_1 = sorted(glob.glob(path_to_files+'eit_l1*'))\n",
    "filenames_euvil_1 = sorted(glob.glob(path_to_files+'*eu_L.fts'))\n",
    "filenames_euvir_1 = sorted(glob.glob(path_to_files+'*eu_R.fts'))\n",
    "# Benoit: Needs fixing\n",
    "filenames_eit_2 = sorted(glob.glob(path_to_files+'eit_l1*'))\n",
    "filenames_euvil_2 = sorted(glob.glob(path_to_files+'*eu_L.fts'))\n",
    "filenames_euvir_2 = sorted(glob.glob(path_to_files+'*eu_R.fts'))\n",
    "# Nb. of samples to work with\n",
    "nb_files = len(filenames_euvil_0)\n",
    "\n",
    "# Hamada class for homogenization\n",
    "filename = 'cumulative_hist.npz'\n",
    "hamada_model = hamada_hist_matching.hamada(filename='cumulative_hist.npz')\n",
    "\n",
    "# Output\n",
    "output_path = ''\n",
    "\n",
    "for file_nb in range(nb_files):\n",
    "    \n",
    "    # Make map objects for one channel\n",
    "    eit_maps = sunpy.map.Map(filenames_eit_0[file_nb])\n",
    "    euvil_maps = sunpy.map.Map(filenames_euvil_0[file_nb])\n",
    "    euvir_maps = sunpy.map.Map(filenames_euvir_0[file_nb])\n",
    "    filename_extract = filenames_eit_0[file_nb].split(path_to_files)\n",
    "    filename_output = output_path + 'composite_' + filename_extract[1]\n",
    "\n",
    "    if eit_maps.observatory in ['SOHO']:\n",
    "        new_coords = get_horizons_coord(eit_maps.observatory.replace(' ', '-'),\n",
    "                                        eit_maps.date)\n",
    "        eit_maps.meta['HGLN_OBS'] = new_coords.lon.to('deg').value\n",
    "        eit_maps.meta['HGLT_OBS'] = new_coords.lat.to('deg').value\n",
    "        eit_maps.meta['DSUN_OBS'] = new_coords.radius.to('m').value\n",
    "        eit_maps.meta.pop('hec_x')\n",
    "        eit_maps.meta.pop('hec_y')\n",
    "        eit_maps.meta.pop('hec_z')\n",
    "    \n",
    "    # Check positioning of instruments in order to cover full Sun\n",
    "    long_eit = eit_maps.observer_coordinate.lon.to('degree')\n",
    "    print(long_eit.value)\n",
    "    long_euvil = euvil_maps.observer_coordinate.lon.to('degree')-long_eit\n",
    "    print(long_euvil.value)\n",
    "    long_euvir = euvir_maps.observer_coordinate.lon.to('degree')-long_eit\n",
    "    print(long_euvir.value)\n",
    "    if -90 < long_euvil.value < 90 and -90 < long_euvir.value < 90:\n",
    "        position_condition = 0\n",
    "    elif 90 < long_euvil.value < 180 and long_euvil.value-180 < long_euvir.value < 180:\n",
    "        position_condition = 0\n",
    "    elif 90 < long_euvir.value < 180 and long_euvir.value-180 < long_euvil.value < 180:\n",
    "        position_condition = 0\n",
    "    elif -180 < long_euvil.value < -90 and -180 < long_euvir.value < long_euvil.value+180:\n",
    "        position_condition = 0\n",
    "    elif -180 < long_euvir.value < -90 and -180 < long_euvil.value < long_euvir.value+180:\n",
    "        position_condition = 0\n",
    "    else:\n",
    "        position_condition = 1\n",
    "    \n",
    "    # If positioning is ideal, continue # MODIFY\n",
    "    if position_condition == 1:\n",
    "        \n",
    "        # continue\n",
    "        for channel_nb in range(nb_channels):\n",
    "            # Make map objects\n",
    "            if channel_nb == 1:\n",
    "                eit_maps = sunpy.map.Map(filenames_eit_1[file_nb])\n",
    "                euvil_maps = sunpy.map.Map(filenames_euvil_1[file_nb])\n",
    "                euvir_maps = sunpy.map.Map(filenames_euvir_1[file_nb])\n",
    "                filename_extract = filenames_eit_1[file_nb].split(path_to_files)\n",
    "                filename_output = output_path + 'composite_' + filename_extract[1]\n",
    "            elif channel_nb == 2:\n",
    "                eit_maps = sunpy.map.Map(filenames_eit_2[file_nb])\n",
    "                euvil_maps = sunpy.map.Map(filenames_euvil_2[file_nb])\n",
    "                euvir_maps = sunpy.map.Map(filenames_euvir_2[file_nb])\n",
    "                filename_output = output_path+'composite_' + filenames_eit_2[file_nb]\n",
    "                filename_extract = filenames_eit_2[file_nb].split(path_to_files)\n",
    "                filename_output = output_path + 'composite_' + filename_extract[1]\n",
    "                \n",
    "            # Properties\n",
    "            nx_eit, ny_eit = eit_maps.data.shape\n",
    "            nx_euvil, ny_euvil = euvil_maps.data.shape\n",
    "            nx_euvir, ny_euvir = euvir_maps.data.shape\n",
    "            \n",
    "            # Adjust SoHO if not already done\n",
    "            if channel_nb > 0 and eit_maps.observatory in ['SOHO']:\n",
    "                new_coords = get_horizons_coord(eit_maps.observatory.replace(' ', '-'),\n",
    "                                                eit_maps.date)\n",
    "                eit_maps.meta['HGLN_OBS'] = new_coords.lon.to('deg').value\n",
    "                eit_maps.meta['HGLT_OBS'] = new_coords.lat.to('deg').value\n",
    "                eit_maps.meta['DSUN_OBS'] = new_coords.radius.to('m').value\n",
    "                eit_maps.meta.pop('hec_x')\n",
    "                eit_maps.meta.pop('hec_y')\n",
    "                eit_maps.meta.pop('hec_z')\n",
    "\n",
    "            # Mask everything outside the solar disk\n",
    "            where_mask = mask_outside_disk(eit_maps)\n",
    "            eit_maps.data[where_mask] = np.nan\n",
    "            where_mask = mask_outside_disk(euvil_maps)\n",
    "            euvil_maps.data[where_mask] = np.nan\n",
    "            where_mask = mask_outside_disk(euvir_maps)\n",
    "            euvir_maps.data[where_mask] = np.nan\n",
    "            \n",
    "            # Wavelet enchancement of the EIT data for improved contrast\n",
    "            # Missing Step ######################\n",
    "            # arr_tmp = eit_maps.data\n",
    "            # eit_maps.data = wavelet_enhancement(arr_tmp)\n",
    "            # Homogenization of the EIT data /w respect to EUVI\n",
    "            arr_tmp = eit_maps.data\n",
    "            where_mask = np.isfinite(arr_tmp)\n",
    "            arr_tmp = hamada_model.hist_matching(arr_tmp, channel_nb)\n",
    "            eit_maps.data[where_mask] = arr_tmp[where_mask]\n",
    "            \n",
    "            # Combined maps\n",
    "            maps = [eit_maps, euvil_maps, euvir_maps]\n",
    "            \n",
    "            # Combined maps\n",
    "            shape_out = (180, 360)  # This is set deliberately low to reduce memory consumption\n",
    "            header = sunpy.map.make_fitswcs_header(shape_out,\n",
    "                                                   SkyCoord(0, 0, unit=u.deg,\n",
    "                                                            frame=\"heliographic_stonyhurst\",\n",
    "                                                            obstime=maps[0].date),\n",
    "                                                   scale=[180 / shape_out[0],\n",
    "                                                          360 / shape_out[1]] * u.deg / u.pix,\n",
    "                                                   wavelength=int(maps[0].meta['wavelnth']) * u.AA,\n",
    "                                                   projection_code=\"CAR\")\n",
    "            out_wcs = WCS(header)\n",
    "            coordinates = tuple(map(sunpy.map.all_coordinates_from_map, maps))\n",
    "            weights = [coord.transform_to(\"heliocentric\").z.value for coord in coordinates]\n",
    "            weights = [(w / np.nanmax(w)) ** 3 for w in weights]\n",
    "            for w in weights:\n",
    "                w[np.isnan(w)] = 0\n",
    "            \n",
    "            array, _ = reproject_and_coadd(maps, out_wcs, shape_out,\n",
    "                                           input_weights=weights,\n",
    "                                           reproject_function=reproject_interp,\n",
    "                                           match_background=True,\n",
    "                                           background_reference=0)\n",
    "        \n",
    "            outmap = sunpy.map.Map((array, header))\n",
    "            outmap.plot_settings = maps[0].plot_settings\n",
    "            outmap.nickname = 'AIA + EUVI/A + EUVI/B'\n",
    "        \n",
    "            # Output\n",
    "            outmap.save(filename_output, filetype='fits', overwrite=True)\n",
    "        \n",
    "#############\n",
    "# End of file\n",
    "#############\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
